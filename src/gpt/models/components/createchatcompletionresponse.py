"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from .chatcompletionresponsemessage import ChatCompletionResponseMessage
from .completionusage import CompletionUsage
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from gpt import utils
from typing import List, Optional

class FinishReason(str, Enum):
    r"""The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    `length` if the maximum number of tokens specified in the request was reached,
    `content_filter` if content was omitted due to a flag from our content filters,
    `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
    """
    STOP = 'stop'
    LENGTH = 'length'
    TOOL_CALLS = 'tool_calls'
    CONTENT_FILTER = 'content_filter'
    FUNCTION_CALL = 'function_call'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TopLogprobs:
    bytes: Optional[List[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bytes') }})
    r"""A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token."""
    logprob: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logprob'), 'exclude': lambda f: f is None }})
    r"""The log probability of this token."""
    token: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('token'), 'exclude': lambda f: f is None }})
    r"""The token."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class CreateChatCompletionResponseContent:
    bytes: Optional[List[int]] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bytes') }})
    r"""A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token."""
    logprob: float = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logprob') }})
    r"""The log probability of this token."""
    token: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('token') }})
    r"""The token."""
    top_logprobs: List[TopLogprobs] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('top_logprobs') }})
    r"""List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Logprobs:
    r"""Log probability information for the choice."""
    content: Optional[List[CreateChatCompletionResponseContent]] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('content') }})
    r"""A list of message content tokens with log probability information."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Choices:
    finish_reason: FinishReason = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('finish_reason') }})
    r"""The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    `length` if the maximum number of tokens specified in the request was reached,
    `content_filter` if content was omitted due to a flag from our content filters,
    `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
    """
    index: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('index') }})
    r"""The index of the choice in the list of choices."""
    logprobs: Optional[Logprobs] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logprobs') }})
    r"""Log probability information for the choice."""
    message: ChatCompletionResponseMessage = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('message') }})
    r"""A chat completion message generated by the model."""
    


class CreateChatCompletionResponseObject(str, Enum):
    r"""The object type, which is always `chat.completion`."""
    CHAT_COMPLETION = 'chat.completion'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class CreateChatCompletionResponse:
    r"""Represents a chat completion response returned by model, based on the provided input."""
    choices: List[Choices] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('choices') }})
    r"""A list of chat completion choices. Can be more than one if `n` is greater than 1."""
    created: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('created') }})
    r"""The Unix timestamp (in seconds) of when the chat completion was created."""
    id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id') }})
    r"""A unique identifier for the chat completion."""
    model: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('model') }})
    r"""The model used for the chat completion."""
    object: CreateChatCompletionResponseObject = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('object') }})
    r"""The object type, which is always `chat.completion`."""
    system_fingerprint: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('system_fingerprint'), 'exclude': lambda f: f is None }})
    r"""This fingerprint represents the backend configuration that the model runs with.

    Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
    """
    usage: Optional[CompletionUsage] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('usage'), 'exclude': lambda f: f is None }})
    r"""Usage statistics for the completion request."""
    

